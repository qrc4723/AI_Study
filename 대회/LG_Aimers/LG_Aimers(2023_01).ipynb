{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjUkQ1i6tHwu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "seed_everything(37) # Seed 고정"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('./drive/MyDrive/dacon_train.csv') #파일 로드드\n",
        "test_df = pd.read_csv('./drive/MyDrive/dacon_test.csv')"
      ],
      "metadata": {
        "id": "0G6MRVMYtUnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
        "train_y = train_df['Y_Quality']\n",
        "train_y1 = train_df['Y_Class']\n",
        "\n",
        "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])\n",
        "\n",
        "\n",
        "train_x = train_x.fillna(0)\n",
        "test_x = test_x.fillna(0)\n",
        "train_x"
      ],
      "metadata": {
        "id": "i9U16A8-tVTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler #표준화\n",
        "\n",
        "std = StandardScaler()\n",
        "std.fit(train_x.filter(regex='X'))\n",
        "train_x_std = std.transform(train_x.filter(regex='X'))\n",
        "test_x_std = std.transform(test_x.filter(regex='X'))\n",
        "train_x.iloc[:, 2:] = train_x_std\n",
        "test_x.iloc[:, 2:] = test_x_std"
      ],
      "metadata": {
        "id": "1ebXjqNRtgfU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qual_col = ['LINE', 'PRODUCT_CODE'] # 라벨 인코딩딩\n",
        "\n",
        "for i in qual_col:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(train_x[i])\n",
        "    train_x[i] = le.transform(train_x[i])\n",
        "\n",
        "    for label in np.unique(test_x[i]):\n",
        "        if label not in le.classes_:\n",
        "            le.classes_ = np.append(le.classes_, label)\n",
        "    test_x[i] = le.transform(test_x[i])\n",
        "\n",
        "train_x"
      ],
      "metadata": {
        "id": "_5AiEbp6tkLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.2, random_state=37) # 모델 정확도 측정을 위한 데이터 스플릿릿\n",
        "\n",
        "y_train1, y_test1 = train_test_split(train_y1, test_size = 0.2, random_state=37)"
      ],
      "metadata": {
        "id": "FUzp-CRZtwBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bayesian-optimization\n",
        "pip install catboost"
      ],
      "metadata": {
        "id": "5VkVVuUduHN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "\n",
        "# 파라미터 튜닝닝\n",
        "def mean_absolute_percentage_error(y_test, y_pred):\n",
        "    y_test, y_pred = np.array(y_test), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "# 탐색 대상 함수 (XGBRegressor)\n",
        "def XGB_cv(max_depth,learning_rate, n_estimators, min_child_samples, bagging_temperature, random_strength, subsample, l2_leaf_reg\n",
        "            ,colsample_bylevel, silent=True):\n",
        "\n",
        "    # 모델 정의\n",
        "    model = CatBoostRegressor(max_depth=int(max_depth),\n",
        "                              learning_rate=learning_rate,\n",
        "                              n_estimators=int(n_estimators),\n",
        "                              bagging_temperature = bagging_temperature,\n",
        "                              random_strength = random_strength,\n",
        "                              min_child_samples=int(min_child_samples),\n",
        "                              subsample=subsample,\n",
        "                              colsample_bylevel=colsample_bylevel,\n",
        "                              l2_leaf_reg = l2_leaf_reg,\n",
        "                              loss_function='RMSE'\n",
        "                              )\n",
        "    # 모델 훈련\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # 예측값 출력\n",
        "    y_pred= model.predict(x_test)\n",
        "\n",
        "    # 각종 metric 계산\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # 오차 최적화로 사용할 metric 반환\n",
        "    return r2 + rmse\n",
        "\n",
        "#  bayesian-optimization 라이브러리의 BayesianOptimization 클래스 import\n",
        "from bayes_opt import BayesianOptimization\n",
        "import numpy as np\n",
        "\n",
        "# 실험해보고자하는 hyperparameter 집합\n",
        "pbounds = {'max_depth': (1, 7),\n",
        "              'learning_rate': (0.01, 0.2),\n",
        "              'n_estimators': (5000, 20000),\n",
        "              'min_child_samples': (1, 50),\n",
        "              'random_strength': (0, 200),\n",
        "              'bagging_temperature': (0.01, 255),\n",
        "              'subsample': (0.2, 1),\n",
        "              'colsample_bylevel' :(0.2, 1),\n",
        "              'l2_leaf_reg' : (1, 200)\n",
        "              }\n",
        "\n",
        "\n",
        "# verbose = 2 항상 출력, verbose = 1 최댓값일 때 출력, verbose = 0 출력 안함\n",
        "bo=BayesianOptimization(f=XGB_cv, pbounds=pbounds, verbose=2, random_state=37 )    \n",
        "\n",
        "# init_points :  초기 Random Search 갯수\n",
        "# n_iter : 반복 횟수 (몇개의 입력값-함숫값 점들을 확인할지! 많을 수록 정확한 값을 얻을 수 있다.)\n",
        "# acq : Acquisition Function들 중 Expected Improvement(EI) 를 사용\n",
        "# xi : exploration 강도 (기본값은 0.0)\n",
        "bo.maximize(init_points=2, n_iter=20, acq='ei', xi=0.01)\n",
        "\n",
        "# ‘iter’는 반복 회차, ‘target’은 목적 함수의 값, 나머지는 입력값을 나타냅니다. \n",
        "# 현재 회차 이전까지 조사된 함숫값들과 비교하여, 현재 회차에 최댓값이 얻어진 경우, \n",
        "\n",
        "# 찾은 파라미터 값 확인\n",
        "print(bo.max)"
      ],
      "metadata": {
        "id": "q6IzprsMuOHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# test데이터 넣기 전 나눈 train 데이터를 토대로 모델 성능 살펴보기기\n",
        "model = CatBoostRegressor(l2_leaf_reg = 30,bagging_temperature= 8.338089576931216, colsample_bylevel= 0.3705090418296811, learning_rate= 0.05824132807180273, max_depth= 5, min_child_samples= 17.32446440935138, n_estimators= 9847, random_strength= 70.01987348280203, subsample= 0.4185277051886087, loss_function='MAE')\n",
        "# train the model\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred2 = model.predict(x_test)\n",
        "print(y_pred2)\n",
        "print(r2_score(y_test, y_pred2))\n",
        "\n",
        "x = np.array(y_train)\n",
        "test = np.array(y_pred2)\n",
        "\n",
        "xgboost1 = XGBClassifier(random_state = 37, colsample_bytree= 0.8202199218715005, learning_rate= 0.011507229876304158, max_depth= 4, min_child_weight= 0.3320122820098772, n_estimators= 6577, subsample= 0.5896753878923751)\n",
        "xgboost1.fit(x.reshape(-1, 1), y_train1)\n",
        "y_pred3 = xgboost1.predict(test.reshape(-1, 1))\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "print(y_pred3)\n",
        "print(precision_score(y_test1, y_pred3, average='micro'))\n",
        "print(precision_score(y_test1, y_pred3, average='macro'))\n",
        "print(precision_score(y_test1, y_pred3, average='weighted'))"
      ],
      "metadata": {
        "id": "W7sWuWjhu1U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 실제 test 데이터를 집어 넣기기\n",
        "\n",
        "model = CatBoostRegressor(l2_leaf_reg = 30,bagging_temperature= 8.338089576931216, colsample_bylevel= 0.3705090418296811, learning_rate= 0.05824132807180273, max_depth= 5, min_child_samples= 17.32446440935138, n_estimators= 9847, random_strength= 70.01987348280203, subsample= 0.4185277051886087, loss_function='RMSE')\n",
        "# train the model\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "y_pred = model.predict(test_x)\n",
        "print(y_pred)\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "x = np.array(train_y)\n",
        "test = np.array(y_pred)\n",
        "\n",
        "xgboost1 = XGBClassifier(random_state = 37, colsample_bytree= 0.8202199218715005, learning_rate= 0.011507229876304158, max_depth= 4, min_child_weight= 0.3320122820098772, n_estimators= 6577, subsample= 0.5896753878923751)\n",
        "xgboost1.fit(x.reshape(-1, 1), train_y1)\n",
        "y_pred1 = xgboost1.predict(test.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "ub4AOJcJv9-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv('./drive/MyDrive/sample_submission.csv')\n",
        "\n",
        "submit['Y_Class'] = y_pred1\n",
        "\n",
        "submit.to_csv('./baseline_submission26.csv', index=False)"
      ],
      "metadata": {
        "id": "WVCABW47wL8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "16V-u8gAvbTg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}